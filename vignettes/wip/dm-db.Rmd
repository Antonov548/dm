---
title: "{dm} and databases"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{{dm} and databases}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options:
  chunk_output_type: console
---


``````{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
fansi::set_knit_hooks(knitr::knit_hooks)
options(crayon.enabled = TRUE, width = 75, cli.width = 75)

knit_print.grViz <- function(x, ...) {
  x %>%
    DiagrammeRsvg::export_svg() %>%
    c("`````{=html}\n", ., "\n`````\n") %>%
    knitr::asis_output()
}
``````




``````{r }
library(dm)
``````


## Connecting to a database

A dm object can be created from a database which is accessible via {DBI}.
When a dm object is created it can either import all the tables in the database, or a limited set provided as a list to the `tables` argument.
For some databases, such as Postgres and SQL Server, primary and foreigh keys are also imported and do not have to be manually added afterwards.

To demonstrate, we connect to a [relational dataset repository](https://relational.fit.cvut.cz/) with a database server that is publicly accessible without registration.
There is a [financial dataset](https://relational.fit.cvut.cz/dataset/Financial) that contains loan data, along with relevant information and transactions.
We chose this loan dataset because the relationships between `loan`, `account`, `transactions` tables are a good representation of databases that record real-world business transactions.
The DBI interface for the repository's MariaDB server does not import primary or foreign keys, so we will need to add them.

Creating a dm object takes a single call to `dm_from_src()`.

``````{r }
library(RMariaDB)
my_db <- dbConnect(
  MariaDB(),
  user = 'guest',
  password = 'relational',
  dbname = 'Financial_ijs',
  host = 'relational.fit.cvut.cz'
)
my_dm <- dm_from_src(my_db)

my_dm
``````

The components of the my_dm object are lazy tables powered by {[dbplyr](https://dbplyr.tidyverse.org/)}.
{dbplyr} translates the {[dplyr](https://dplyr.tidyverse.org/)} grammar of data manipulation into queries the database server understands.
Lazy tables defer downloading of table data until results are collected for printing or local processing.

## Building a dm from tables

A dm can also be constructed from individual tables or views.
This is useful for when you want to work with a subset of a database's tables, perhaps from different schemas.

Below we use the `tbl()` function from {dplyr} to extract two tables from the financial database.
Then we create our dm by passing the tables in an as arguments.

``````{r }
dbListTables(my_db)

library(dbplyr)
loans <- tbl(my_db, "loans")
accounts <- tbl(my_db, "accounts")

my_manual_dm <- dm(loans, accounts)
my_manual_dm
``````

## Define Primary and Foreign Keys

Primary and Foreign Keys are how relational database tables are linked with each other.
A primary key is a column that has a unique value for each row within a table.
A foreign key is a column containing the primary key for a row in another table.[^compound]

[^compound]: Support for compound keys (consisting of multiple columns) is [planned](https://github.com/krlmlr/dm/issues/3).
Foreign keys act as cross references between tables.
They specify the relationships that gives us the *relational* database.

The [model diagram](https://relational.fit.cvut.cz/assets/img/datasets-generated/financial.svg) provided by our test database loosely illustrates the intended relationships between tables.
In the diagram we can see that the loans table should be linked to the accounts table.
Below we create those links in 3 steps:

1. Add a primary key `id` to the accounts table
1. Add a primary key `id` to the loans table
1. Add a foreign key `account_id` to the loans table referencing the accounts table

Then we assign colors to the tables and draw the structure of the dm.

Note that when the foreign key is created the primary key in the referenced table does not need to be specified, but this does require primary keys to be defined first.
And, as mentioned above, primary and foreign key constraints on the database are currently only imported for Postgres and SQL Server databases.
This process of key definition needs to be done manually for other databases
    
``````{r }
my_dm_keys <-
  my_manual_dm %>%
  dm_add_pk(accounts, id) %>%
  dm_add_pk(loans, id) %>%
  dm_add_fk(loans, account_id, accounts) %>%
  dm_set_colors(green = loans, orange = accounts)

my_dm_keys %>%
  dm_draw()
``````

Once you have instantiated a dm object you can continue to add tables to it.
For tables from the original source for the dm, use `dm_add_tbl()`

``````{r }
trans <- tbl(my_db, "trans")

my_dm_keys %>%
  dm_add_tbl(trans)
``````

For tables from other sources or from the local environment `dplyr::copy_to()` is used.
`copy_to()` is discussed later in this article.

## Transient nature of operations

Like other R objects, a dm is immutable and all operations performed on it are transient unless stored in a new variable.

``````{r }
my_dm_keys

my_dm_trans <-
  my_dm_keys %>%
  dm_add_tbl(trans)

my_dm_trans
``````

And, like {dbplyr}, results are never written to a database unless explicitly requested.

#ASK KIRILL - what exactly is happening here
- Example: flattening operation and its translation to SQL

``````{r }
my_dm_keys %>%
  dm_flatten_to_tbl(loans)

my_dm_keys %>%
  dm_flatten_to_tbl(loans) %>%
  sql_render()
``````

## Performing operations on tables by "zooming"

As the dm is a collection of tables, if we wish to perform operations on an individual table we set it as the context for those operations using `dm_zoom_to()`.
See `vignette("dm-zoom-to-table", package = "dm")` for more detail on zooming.

Since dm operations are transient unless explicitly requested, our chain of manipulations on the selected table are made permanent by copying it into a new table at completion with `dm_insert_zoomed()`.

``````{r }
my_dm_total <-
  my_dm_keys %>%
  dm_zoom_to(loans) %>%
  group_by(account_id) %>%
  summarize(total_amount = sum(amount, na.rm = TRUE)) %>%
  ungroup() %>%
  dm_insert_zoomed("total_loans")

my_dm_total$total_loans

my_dm_total %>%
  dm_draw()

my_dm_total$total_loans %>%
  sql_render()
``````


## Persisting results

After adding columns to link tables or calculating summaries of data, we might want these changes to the database to persist. 
#FIXME - if compute stores results in temporary tables, how are they made permanent or inserted into the database itself?

To force a dm to execute the SQL query generated by the operations it has performed, we use the `compute()` function, originally implemented in {dbplyr}, but reimplimented in {dm} to provide the same functionality.
#FIXME - what's the right language here? inherited? carried over from?

`compute()` forces the computation of a query, in this case the query or multiple queries created by the dm to represent all operations that have been performed but not yet evaluated.
The results are stored in temporary tables on the database server.
Calling `compute()` requires write access, otherwise an error is returned.

relational.fit.cvut.cz does not allow write access. 
As a workaround to demonstrate the usage of `compute()`, we FIXME use `dm_financial_sqlite()` FIXME.

``````{r }
library(RSQLite)
my_dm_sqlite <- dm_financial_sqlite()

my_dm_total <-
  my_dm_sqlite %>%
  dm_zoom_to(loans) %>%
  group_by(account_id) %>%
  summarize(total_amount = sum(amount, na.rm = TRUE)) %>%
  ungroup() %>%
  dm_insert_zoomed("total_loans")
``````


Two dbplyr verbs have been implemented for dm objects, retaining their meaning.
`compute()`, as mentioned above, materializes all tables into new (temporary or persistent) tables.

``````{r }
my_dm_total_computed <-
  my_dm_total %>%
  compute()

my_dm_total_computed$total_loans

my_dm_total_computed$total_loans %>%
  sql_render()
``````

`collect()` downloads all tables to local data frames.

``````{r }
my_dm_local <-
  my_dm_total %>%
  collect()

my_dm_local$total_loans
``````

There is a third {dbplyr} verb that has not yet been implemented. `collapse()` forces generation of the SQL query instead of computation ([#304](https://github.com/krlmlr/dm/issues/304)).

`compute()` also works for a zoomed dm.
Calling it during a chain of operations will execute all relevant SQL queries up to that point.
Operations after the `compute()` will use the generated results.
#FIXME - is this true? Is this what is happening?


``````{r }
my_dm_total_inplace <-
  my_dm_sqlite %>%
  dm_zoom_to(loans) %>%
  group_by(account_id) %>%
  summarize(total_amount = sum(amount, na.rm = TRUE)) %>%
  ungroup() %>%
  compute() %>%
  dm_insert_zoomed("total_loans")

my_dm_total_inplace$total_loans %>%
  sql_render()
``````


## Deploying a dm to a database

We have already seen an example of copying a dm from one data source to another.
We deployed our dm based on a remote database server to a local SQLite database using `copy_dm_to()`.
The function takes as its first argument a {DBI} connection, in the example it is the `SQLite()` DBI driver, and a dm as its second argument.
The dm is copied to the DBI connection and new dm, with the DBI connection as its source, is returned.

The default behaviour is to create temporary tables and, where possible (currently Postgres and SQL server), key constraints will be set.

## Conclusion

#TBD

FIXME:

- Describe `copy_to()`
- Mention `temporary` argument for persistent deployment
- Deployment: describe `copy_dm_to()`
